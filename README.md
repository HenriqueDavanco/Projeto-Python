ğŸš€ Pipeline de CotaÃ§Ãµes Cambiais com Python + LLM
Este projeto implementa uma pipeline completa para coletar, processar e analisar taxas de cÃ¢mbio, integrando um modelo de linguagem grande (LLM) para gerar insights executivos. O projeto foi desenvolvido como parte do MBA em Data Engineering, focado em "Python Programming for Data Engineers".

âœ¨ Objetivo do Projeto
O principal objetivo Ã© demonstrar a construÃ§Ã£o de uma pipeline de dados end-to-end, cobrindo:

IngestÃ£o: Coleta de dados de taxas de cÃ¢mbio da API https://www.exchangerate-api.com/.

TransformaÃ§Ã£o: NormalizaÃ§Ã£o e validaÃ§Ã£o dos dados, garantindo sua qualidade.

Carga: Armazenamento dos dados processados em formato Parquet na camada gold.

Enriquecimento com LLM: GeraÃ§Ã£o de resumos e insights em linguagem natural, utilizando o Google Gemini, voltados para usuÃ¡rios de negÃ³cio.

Testes e Observabilidade: ImplementaÃ§Ã£o de testes unitÃ¡rios e logging estruturado para garantir a robustez e monitoramento da pipeline.

ğŸ“¦ Estrutura do Projeto


â”œâ”€â”€ src/                      # CÃ³digo fonte da pipeline
â”‚   â”œâ”€â”€ ingest.py             # Coleta de dados da API
â”‚   â”œâ”€â”€ transform.py          # NormalizaÃ§Ã£o e validaÃ§Ã£o
â”‚   â”œâ”€â”€ load.py               # Carregamento para Parquet
â”‚   â”œâ”€â”€ llm_enrichment.py     # IntegraÃ§Ã£o com a LLM (Google Gemini)
â”‚   â”œâ”€â”€ utils.py              # FunÃ§Ãµes auxiliares (configuraÃ§Ã£o, logging)
â”‚   â””â”€â”€ main.py               # Orquestrador principal (executa a pipeline)
â”œâ”€â”€ raw/                      # Dados JSON brutos da API
â”œâ”€â”€ silver/                   # Dados normalizados (opcional, para depuraÃ§Ã£o)
â”œâ”€â”€ gold/                     # Dados finais em formato Parquet
â”œâ”€â”€ reports/                  # RelatÃ³rios/insights gerados pela LLM
â”œâ”€â”€ .env                      # VariÃ¡veis de ambiente (chaves de API)
â”œâ”€â”€ requirements.txt          # DependÃªncias do Python
â”œâ”€â”€ README.md                 # DocumentaÃ§Ã£o do projeto
â””â”€â”€ tests/                    # Testes unitÃ¡rios
    â”œâ”€â”€ test_ingest.py        # Testes para a etapa de ingestÃ£o
    â”œâ”€â”€ test_transform.py     # Testes para a etapa de transformaÃ§Ã£o
    â””â”€â”€ __init__.py           # Inicializa o diretÃ³rio como pacote Python


    

âš™ï¸ Setup e ConfiguraÃ§Ã£o
Siga os passos abaixo para configurar e executar o projeto.

1. Clonar o RepositÃ³rio (Exemplo)
git clone <URL_DO_SEU_REPOSITORIO>
cd pipeline-cotacoes-cambiais

2. Criar e Ativar o Ambiente Virtual
Ã‰ altamente recomendado usar um ambiente virtual para gerenciar as dependÃªncias.

python -m venv venv
# No Windows
.\venv\Scripts\activate
# No macOS/Linux
source venv/bin/activate

3. Instalar as DependÃªncias
pip install -r requirements.txt

4. Configurar VariÃ¡veis de Ambiente (.env)
Crie um arquivo chamado .env na raiz do projeto (no mesmo nÃ­vel do README.md) e adicione suas chaves de API:

EXCHANGE_RATE_API_KEY=SUA_CHAVE_DA_EXCHANGERATE_API
GEMINI_API_KEY=SUA_CHAVE_DA_API_GEMINI

EXCHANGE_RATE_API_KEY: Obtenha esta chave registrando-se gratuitamente em exchangerate-api.com.

GEMINI_API_KEY: Obtenha esta chave atravÃ©s do Google AI Studio ou da console do Google Cloud.

â–¶ï¸ Como Executar
ApÃ³s o setup, vocÃª pode executar a pipeline completa atravÃ©s do script main.py:

python src/main.py

Ao executar, vocÃª verÃ¡ logs estruturados no console, indicando o progresso e o status de cada etapa. Os relatÃ³rios gerados pela LLM serÃ£o impressos no console e salvos na pasta reports/.

âœ… Testes
Para executar os testes unitÃ¡rios, certifique-se de que o pytest estÃ¡ instalado (incluÃ­do no requirements.txt) e execute a partir da raiz do projeto:

pytest tests/

Isso executarÃ¡ todos os testes definidos na pasta tests/ e reportarÃ¡ os resultados.

ğŸ“‹ EntregÃ¡veis
CÃ³digo no GitHub: O repositÃ³rio contÃ©m todo o cÃ³digo fonte da pipeline.

README.md: Este documento detalha o setup, execuÃ§Ã£o e configuraÃ§Ã£o.

Arquivos Finais (/gold/): ContÃªm os dados de cotaÃ§Ãµes cambiais limpos e processados em formato Parquet.

Exemplo: gold/exchange_rates_YYYY-MM-DD.parquet

RelatÃ³rios/insights da LLM (/reports/): Arquivos JSON contendo os resumos e detalhes gerados pela LLM.

Exemplo: reports/llm_insights_YYYY-MM-DD.json

ğŸ“Š CritÃ©rios de AvaliaÃ§Ã£o Atendidos
30% Pipeline (ETL completo): ImplementaÃ§Ã£o das etapas de IngestÃ£o (ingest.py), TransformaÃ§Ã£o (transform.py) e Carga (load.py) com fluxo orquestrado por main.py.

15% Qualidade e robustez (testes + logging):

Testes UnitÃ¡rios: Presentes na pasta tests/, cobrindo as validaÃ§Ãµes de dados e o fluxo de ingestÃ£o/transformaÃ§Ã£o.

Logging Estruturado: UtilizaÃ§Ã£o da biblioteca logging com formato JSON (src/utils.py), registrando informaÃ§Ãµes (INFO) e erros (ERROR) em todas as etapas, incluindo o logging de prompt/response da LLM para auditoria.

15% DocumentaÃ§Ã£o e clareza no README: Este README.md fornece instruÃ§Ãµes claras de setup, execuÃ§Ã£o e explica a estrutura do projeto.

10% Uso inteligente/estratÃ©gico da LLM: A LLM (Google Gemini) Ã© utilizada para interpretar o dataset diÃ¡rio, gerando um resumo executivo com a variaÃ§Ã£o das principais moedas e insights acionÃ¡veis para usuÃ¡rios de negÃ³cio, conforme o requisito do projeto.

15% Criatividade extra (ex.: dashboards ou anÃ¡lises adicionais): (Opcional - Adicione aqui se implementar um dashboard Streamlit, por exemplo.)

ğŸ—“ï¸ Regras de Entrega e ApresentaÃ§Ã£o

Este projeto estÃ¡ configurado para ser entregue com o cÃ³digo no GitHub e este README.md completo. A apresentaÃ§Ã£o ao vivo seria uma oportunidade para demonstrar o funcionamento da pipeline e os insights gerados.

